{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU（Gated Recurrent Unit）在LSTM进行了改进，结构比LSTM更加精简，比LSTM少了一个Gate，计算效率更高占用内存更小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）GRU将输入门、遗忘门、输出门3个门变为2个：更新门（Update Gate）和重置门（Reset Gate）  \n",
    "2）将单元状态与输出合并成一个状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pics/GRU_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：《Python深度学习基于PyTroch》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Pytorch实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU和LSTM很相似，只是LSTM有3个门2个隐含状态，GRU只有2个门1个隐含状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.cell_size = cell_size # 没有LSTM的cell单元状态\n",
    "        # self.gate = nn.Linear(input_size + hidden_size, cell_size)\n",
    "        self.gate = nn.Linear(input_size + hidden_size, hidden_size) # 从cell_size变为hidden_size\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        z_gate = self.sigmoid(self.gate(combined)) # 更新门 没有输入门\n",
    "        r_gate = self.sigmoid(self.gate(combined)) # 重置门 没有遗忘门\n",
    "        combined01 = torch.cat((input, torch.mul(hidden, r_gate)), 1) # 多了组合\n",
    "        # o_gate = self.sigmoid(self.gate(combined)) # 没有输出门\n",
    "        h1_state = self.tanh(self.gate(combined)) # 从z_state变为h1_state\n",
    "        # cell = torch.add(torch.mul(cell, f_gate), torch.mul(z_state, i_gate)) # 没有计算单元\n",
    "        h_state = torch.add(torch.mul((1-z_gate), hidden), torch.mul(h1_state, z_gate)) # 多了计算状态\n",
    "        output = self.output(hidden) \n",
    "        output = self.softmax(output)\n",
    "        return output, h_state\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_cell = GRUCell(input_size=10, hidden_size=20, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(32, 10)\n",
    "h_0 = torch.randn(32, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hn  = gru_cell(input, h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 10]), torch.Size([32, 20]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
