{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 什么是卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y(t) = f(t) * g(t) = \\int f(\\tau)g(t-\\tau)d\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "傅里叶解决了时域转频域问题：$F[f_1(t)*f_2(t)] = f_1(w)·f_2(w)$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通信：卷积看成信号搬移到另一个频率中的调制过程  \n",
    "物理：系统对某个输入量的影响  \n",
    "电路：线性时不变系统的冲击函数对输入的响应  \n",
    "信号：对信号的滤波，系统就是滤波器\n",
    "图像：平滑、锐化、展宽操作  \n",
    "还有其他领域..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 离散卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如是总分为30分时的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pics/CNN/离散卷积1.png)\n",
    "![](./pics/CNN/离散卷积2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 连续卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面是吃东西吸收的曲线（输入信号），下面是人的消化曲线（单位脉冲响应）  \n",
    "问t时刻时肚子里存有的热量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pics/CNN/连续卷积.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 CNN的发展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://zhuanlan.zhihu.com/p/116197079"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1990年Yann LeCun提出了LeNet用于手写数字识别，Lenet是一个 7 层的神经网络，包含 3 个卷积层，2 个池化层，1 个全连接层。其中所有卷积层的所有卷积核都为 5x5，步长 strid=1，池化方法都为全局 pooling，激活函数为 Sigmoid。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2012年产生了Alex Net，有2400万节点，1.4亿个参数和150亿个连接，Alexnet模型由5个卷积层和3个池化Pooling 层 ，其中还有3个全连接层构成。AlexNet 跟 LeNet 结构类似，但使⽤了更多的卷积层和更⼤的参数空间来拟合⼤规模数据集 ImageNet。**它是浅层神经⽹络和深度神经⽹络的分界线**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014年时产生了VGG，有个16个训练网络，可以认为是加深版的AlexNet，其突出特点是简单，卷积层均采用相同的卷积核参数，池化层的参数均为2×2，步幅stride=2，max的池化方式，模型是由若干卷积层和池化层堆叠（stack）的方式构成，比较容易形成较深的网络结构。概括来说就是: Small filters, Deeper networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014年的GoogleNet是第一名，其使用了Inception模块，它的目的是设计一种具有优良局部拓扑结构的网络，即**对输入图像并行地执行多个卷积运算或池化操作**，并将所有输出结果拼接为一个非常深的特征图。因为 1\\*1、3\\*3 或 5\\*5 等不同的卷积运算与池化操作可以获得输入图像的不同信息，并行处理这些运算并结合所有结果将获得更好的图像表征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2015年ResNet解决了深度CNN难以训练的问题，14年的VGG才19层，而15年的ResNet多达152层，何凯明认为考虑极端情况就是这些增加的网络层什么也不学习，**利用跳跃连接的方式仅仅复制浅层网络的特征，即这样新层是恒等映射（Identity mapping）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016年的Xception利用了**深度可分离卷积Depthwise Separable Convolution**，它在ResNet基础上改进，并优化了Inception的卷积计算:先进行普通卷积操作，再对 1 × 1 卷积后的每个channel分别进行 3 × 3卷积操作，最后将结果 concat，节省了计算量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017年MobileNet是专注于**移动端或者嵌入式设备**的轻量级CNN网络，也利用了深度可分离卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017年DenseNet提出，减轻了梯度消失的问题，有效利用了特征和加强了特征传递，一定程度上也减少了参数量，在传统的卷积神经网络中，如果你有L层，那么就会有L个连接，但是在DenseNet中，会有L(L+1)/2个连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后来Google开始用AutoML搜索出了NasNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
