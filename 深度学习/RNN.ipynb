{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN利用隐藏层能够捕获之前所有时刻发生的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：《Python深度学习基于PyTroch》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Demo实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pics/RNN_demo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2]\n",
    "state = [0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_cell_state = np.array([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "b_cell = np.array([0.1, -0.1])\n",
    "w_output = np.array([1.0, 2.0])\n",
    "b_output = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "状态值_0 [0.53704957 0.46211716]\n",
      "输出值_0 1.561283881518055\n",
      "状态值_1 [0.85973818 0.88366641]\n",
      "输出值_1 2.727071008233731\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    state = np.append(state, X[i]) # 1x3\n",
    "    before_activation = np.dot(state, w_cell_state) + b_cell # 1x2\n",
    "    state = np.tanh(before_activation) # 1X2\n",
    "    final_output = np.dot(state, w_output) + b_output # 1X1\n",
    "    print('状态值_%i' % i, state)\n",
    "    print('输出值_%i' % i, final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Pytorch实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./pics/RNN_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.RNN # pytorch中的RNN使用方式\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 10]), torch.Size([20, 20]), torch.Size([20]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一层相关参数形状\n",
    "# ih_l0是输入（10）到隐藏层状态（20），所以是10x20\n",
    "# hh_l0是状态（20）到状态（20），所以是20x20\n",
    "rnn.weight_ih_l0.shape, rnn.weight_hh_l0.shape, rnn.bias_hh_l0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 20]), torch.Size([20, 20]), torch.Size([20]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二层相关参数形状\n",
    "rnn.weight_ih_l1.shape, rnn.weight_hh_l1.shape, rnn.bias_hh_l1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成输入数据\n",
    "input = torch.randn(100, 32, 10)\n",
    "h_0 = torch.randn(2, 32, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, h_n = rnn(input, h_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 32, 20]), torch.Size([2, 32, 20]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, input_data, hidden):\n",
    "        combined = torch.cat((input_data, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
